Der Aufstieg und das Potenzial gro√üer sprachmodellbasierter Agenten: Eine Umfrage
üî• Pflichtlekt√ºre f√ºr LLM-basierte Agenten.

üèÉ Demn√§chst erh√§ltlich: F√ºgen Sie jeder Arbeit eine Einleitung mit einem Satz hinzu.

üîî Neuigkeiten
ü•≥ [20.09.2023] Dieses Projekt wurde auf GitHub Trendings gelistet ! Es ist eine gro√üe Ehre!
üí• [15.09.2023] Unsere Umfrage ist ver√∂ffentlicht! Siehe ‚ÄûThe Rise and Potential of Large Language Model Based Agents: A Survey‚Äú f√ºr den Artikel!
‚ú® [14.09.2023] Wir erstellen dieses Repository, um eine Papierliste zu LLM-basierten Agenten zu f√ºhren. Weitere Papiere folgen in K√ºrze!

üåü Einf√ºhrung
Seit langem strebt die Menschheit nach k√ºnstlicher Intelligenz (KI), die dem menschlichen Niveau entspricht oder dieses √ºbertrifft, wobei KI-Agenten als vielversprechendes Vehikel f√ºr dieses Streben gelten. KI-Agenten sind k√ºnstliche Einheiten, die ihre Umgebung wahrnehmen, Entscheidungen treffen und Ma√ünahmen ergreifen.

Aufgrund der vielseitigen und bemerkenswerten F√§higkeiten, die sie demonstrieren, gelten gro√üe Sprachmodelle (LLMs) als potenzielle Impulse f√ºr die K√ºnstliche Allgemeine Intelligenz (AGI) und bieten Hoffnung f√ºr die Entwicklung allgemeiner KI-Agenten. Viele Forschungsanstrengungen haben LLMs als Grundlage f√ºr die Entwicklung von KI-Agenten genutzt und erhebliche Fortschritte erzielt.

In diesem Repository bieten wir eine systematische und umfassende √úbersicht √ºber LLM-basierte Agenten und listen einige Artikel auf, die man unbedingt lesen muss.

Konkret beginnen wir mit dem allgemeinen konzeptionellen Rahmen f√ºr LLM-basierte Agenten: Er umfasst drei Hauptkomponenten: Gehirn, Wahrnehmung und Aktion, und der Rahmen kann an verschiedene Anwendungen angepasst werden. Anschlie√üend untersuchen wir die umfangreichen Anwendungen von LLM-basierten Agenten in drei Aspekten: Einzelagentenszenarien, Multiagentenszenarien und Mensch-Agenten-Kooperation. Anschlie√üend befassen wir uns mit Agentengesellschaften und erforschen das Verhalten und die Pers√∂nlichkeit von LLM-basierten Agenten, die sozialen Ph√§nomene, die bei der Bildung von Gesellschaften entstehen, und die Erkenntnisse, die sie f√ºr die menschliche Gesellschaft bieten. Abschlie√üend besprechen wir eine Reihe wichtiger Themen und offene Probleme auf diesem Gebiet.

Wir freuen uns sehr √ºber Beitr√§ge √ºber PRs, Issues, E-Mails oder auf andere Weise.

Inhaltsverzeichnis (ToC)
Der Aufstieg und das Potenzial gro√üer sprachmodellbasierter Agenten: Eine Umfrage
üîî Neuigkeiten
üåü Einf√ºhrung
Inhaltsverzeichnis (ToC)
1. Die Geburt eines Agenten: Aufbau von LLM-basierten Agenten
1.1 Gehirn: Besteht haupts√§chlich aus einem LLM
1.1.1 Interaktion mit nat√ºrlicher Sprache
Hochwertige Generation
Tiefes Verst√§ndnis
1.1.2 Wissen
Pretrain-Modell
Sprachkenntnisse
Gesundes Wissen
Umsetzbares Wissen
M√∂gliche Wissensprobleme
1.1.3 Speicher
Speicherf√§higkeit
Erh√∂hung der L√§ngenbeschr√§nkung von Transformers
Erinnerung zusammenfassen
Komprimieren von Speichern mit Vektoren oder Datenstrukturen
Erinnerungsabruf
1.1.4 Argumentation und Planung
Argumentation
Planung
Planformulierung
Reflexion planen
1.1.5 √úbertragbarkeit und Verallgemeinerung
Ungesehene Aufgabenverallgemeinerung
Lernen im Kontext
Kontinuierliches Lernen
1.2 Wahrnehmung: Multimodale Eingaben f√ºr LLM-basierte Agenten
1.2.1 Visuell
1.2.2 Audio
1.3 Aktion: Aktionsraum von LLM-basierten Agenten erweitern
1.3.1 Werkzeugverwendung
1.3.2 Verk√∂rperte Aktion
2. Agenten in der Praxis: Anwendungen von LLM-basierten Agenten
2.1 Allgemeine F√§higkeiten eines Einzelagenten
2.1.1 Aufgabenorientierte Bereitstellung
2.1.2 Innovationsorientierter Einsatz
2.1.3 Lebenszyklusorientierte Bereitstellung
2.2 Koordinierungspotential mehrerer Agenten
2.2.1 Kooperative Interaktion f√ºr Komplementarit√§t
2.2.2 Gegnerische Interaktion f√ºr den Fortschritt
2.3 Interaktive Interaktion zwischen Mensch und Agent
2.3.1 Instructor-Executor-Paradigma
Ausbildung
Gesundheit
Andere Anwendung
2.3.2 Paradigma der gleichberechtigten Partnerschaft
Einf√ºhlsamer Kommunikator
Teilnehmer auf menschlicher Ebene
3. Agentengesellschaft: Von der Individualit√§t zur Sozialit√§t
3.1 Verhalten und Pers√∂nlichkeit von LLM-basierten Agenten
3.1.1 Sozialverhalten
Individuelle Verhaltensweisen
Gruppenverhalten
3.1.2 Pers√∂nlichkeit
Erkenntnis
Emotion
Charakter
3.2 Umgebung f√ºr die Agentengesellschaft
3.2.1 Textbasierte Umgebung
3.2.2 Virtuelle Sandbox-Umgebung
3.2.3 Physische Umgebung
3.3 Gesellschaftssimulation mit LLM-basierten Agenten
Zitat
Projektbetreuer und Mitwirkende
Kontakt
Sternengeschichte
1. Die Geburt eines Agenten: Aufbau von LLM-basierten Agenten

1.1 Gehirn: Besteht haupts√§chlich aus einem LLM
1.1.1 Interaktion mit nat√ºrlicher Sprache
Hochwertige Generation
[2023/10] Auf dem Weg zu einer durchg√§ngigen verk√∂rperten Entscheidungsfindung √ºber ein multimodales gro√ües Sprachmodell: Erkundungen mit GPT4-Vision und dar√ºber hinaus Liang Chen et al. arXiv. [ Papier ] [ Code ]
Diese Arbeit schl√§gt PCA-EVAL vor, das die verk√∂rperte Entscheidungsfindung mittels MLLM-basierter End-to-End-Methode und LLM-basierter Tool-Using-Methoden auf Wahrnehmungs-, Kognitions- und Aktionsebene bewertet.
[2023/08] Eine mehrsprachige, multimodale Multitasking-Bewertung von ChatGPT in Bezug auf Argumentation, Halluzination und Interaktivit√§t. Yejin Bang et al. arXiv. [ Papier ]
Diese Arbeit bewertet die Multitasking-, Mehrsprachigkeits- und Multimodalaspekte von ChatGPT anhand von 21 Datens√§tzen, die 8 verschiedene g√§ngige NLP-Anwendungsaufgaben abdecken.
[2023/06] LLM-Eval: Einheitliche mehrdimensionale automatische Bewertung f√ºr Open-Domain-Konversationen mit gro√üen Sprachmodellen. Yen-Ting Lin et al. arXiv. [ Papier ]
Die LLM-EVAL-Methode bewertet mehrere Bewertungsdimensionen wie Inhalt, Grammatik, Relevanz und Angemessenheit.
[2023/04] Ist ChatGPT ein hochfl√ºssiges System zur Korrektur grammatikalischer Fehler? Eine umfassende Auswertung. Tao Fang et al. arXiv. [ Papier ]
Die Ergebnisse der Evaluierung zeigen, dass ChatGPT √ºber hervorragende F√§higkeiten zur Fehlererkennung verf√ºgt und Fehler frei korrigieren kann, um die korrigierten S√§tze sehr fl√ºssig zu machen. Dar√ºber hinaus unterstreicht seine Leistung in nicht-englischsprachigen und ressourcenarmen Umgebungen sein Potenzial bei mehrsprachigen GEC-Aufgaben.
Tiefes Verst√§ndnis
[2023/06] Clever Hans oder Neural Theory of Mind? Stresstests des sozialen Denkens in gro√üen Sprachmodellen. Natalie Shapira et al. arXiv. [ Papier ]
LLMs weisen bestimmte F√§higkeiten zur Theorie des Geistes auf, aber dieses Verhalten ist alles andere als robust.
[2022/08] Ableitung von Belohnungen aus der Sprache im Kontext. Jessy Lin et al. ACL. [ Papier ]
Diese Arbeit stellt ein Modell vor, das Belohnungen aus der Sprache ableitet und optimale Aktionen in einer unsichtbaren Umgebung vorhersagt.
[2021/10] Theorie der gedankenbasierten unterst√ºtzenden Kommunikation in der komplexen Mensch-Roboter-Kooperation. Moritz C. Buehler et al. arXiv. [ Papier ]
Diese Arbeit entwirft einen Agenten Sushi mit einem Verst√§ndnis f√ºr den Menschen w√§hrend der Interaktion.
1.1.2 Wissen
Pretrain-Modell
[2023/04] Lernen verteilter Darstellungen von S√§tzen aus unbeschrifteten Daten. Felix Hill (Universit√§t Cambridge) et al. arXiv. [ Papier ]
[2020/02] Wie viel Wissen k√∂nnen Sie in die Parameter eines Sprachmodells packen? Adam Roberts (Google) et al. arXiv. [ Papier ]
[2020/01] Skalierungsgesetze f√ºr neuronale Sprachmodelle. Jared Kaplan (Johns Hopkins University) et al. arXiv. [ Papier ]
[2017/12] Commonsense-Wissen in maschineller Intelligenz. Niket Tandon (Allen Institute for Artificial Intelligence) et al. SIGMOD. [ Papier ]
[2011/03] Verarbeitung nat√ºrlicher Sprache (fast) von Grund auf. Ronan Collobert (Princeton) et al. arXiv. [ Papier ]
Sprachkenntnisse
[2023/02] Eine mehrsprachige, multimodale Multitasking-Bewertung von ChatGPT in Bezug auf Argumentation, Halluzination und Interaktivit√§t. Yejin Bang et al. arXiv. [ Papier ]
[2021/06] Untersuchung vorab trainierter Sprachmodelle auf semantische Attribute und ihre Werte. Meriem Beloucif et al. EMNLP. [ Papier ]
[2020/10] Untersuchung vorab trainierter Sprachmodelle f√ºr die lexikalische Semantik. Ivan Vuliƒá et al. arXiv. [ Papier ]
[2019/04] Eine strukturelle Sonde zum Finden der Syntax in Wortdarstellungen. John Hewitt et al. ACL. [ Papier ]
[2016/04] Verbesserte automatische Schl√ºsselwortextraktion mit mehr semantischem Wissen. H. Leung. Systeme f√ºr fortgeschrittene Anwendungen. [ Papier ]
Gesundes Wissen
[2022/10] Sprachmodelle des Codes sind Few-Shot-Commonsense-Lernende. Aman Madaan et al.arXiv. [ Papier ]
[2021/04] Relationale Weltwissensrepr√§sentation in kontextuellen Sprachmodellen: Ein R√ºckblick. Tara Safavi et al. arXiv. [ Papier ]
[2019/11] Wie k√∂nnen wir wissen, was Sprachmodelle wissen? Zhengbao Jiang et al.arXiv. [ Papier ]
Umsetzbares Wissen
[2023/07] Gro√üe Sprachmodelle in der Medizin. Arun James Thirunavukarasu et al. Natur. [ Papier ]
[2023/06] DS-1000: Ein nat√ºrlicher und zuverl√§ssiger Ma√üstab f√ºr die Generierung von Data Science-Code. Yuhang Lai et al. ICML. [ Papier ]
[2022/10] Sprachmodelle des Codes sind Few-Shot-Commonsense-Lernende. Aman Madaan et al. arXiv. [ Papier ]
[2022/02] Eine systematische Bewertung gro√üer Sprachmodelle von Code. Frank F. Xu et al.arXiv. [ Papier ]
[2021/10] Schulung von Verifizierern zur L√∂sung mathematischer Wortprobleme. Karl Cobbe et al. arXiv. [ Papier ]
M√∂gliche Wissensprobleme
[2023/10] FreshLLMs: Auffrischung gro√üer Sprachmodelle mit Suchmaschinenerweiterung. Tu Vu (Google) et al. arXiv [ Papier ] [ Code ]
[2023/05] Bearbeiten gro√üer Sprachmodelle: Probleme, Methoden und Chancen. Yunzhi Yao et al. arXiv. [ Papier ]
[2023/05] Self-Checker: Plug-and-Play-Module zur Faktenpr√ºfung mit gro√üen Sprachmodellen. Miaoran Li et al. arXiv. [ Papier ]
[2023/05] KRITIK: Gro√üe Sprachmodelle k√∂nnen sich mit Tool-interaktiver Kritik selbst korrigieren. Zhibin Gou et al. arXiv. [ Papier ]
[2023/04] Tool-Lernen mit Grundlagenmodellen. Yujia Qin et al. arXiv. [ Papier ]
[2023/03] SelfCheckGPT: Ressourcenlose Black-Box-Halluzinationserkennung f√ºr generative gro√üe Sprachmodelle. Potsawee Manakul et al. arXiv. [ Papier ]
[2022/06] Speicherbasierte Modellbearbeitung im Ma√üstab. Eric Mitchell et al. arXiv. [ Papier ]
[2022/04] Ein √úberblick √ºber Sprachmodelle als Wissensdatenbanken. Badr AlKhamissi et al.arXiv. [ Papier ]
[2021/04] Bearbeiten von Faktenwissen in Sprachmodellen. Nicola De Cao et al.arXiv. [ Papier ]
[2017/08] Messung des katastrophalen Vergessens in neuronalen Netzen. Ronald Kemker et al.arXiv. [ Papier ]
1.1.3 Speicher
Speicherf√§higkeit
Erh√∂hung der L√§ngenbeschr√§nkung von Transformers
[2023/10] MemGPT: Auf dem Weg zu LLMs als Betriebssystemen. Charles Packer (UC Berkeley) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Datensatz ]
[2023/05] Randomisierte Positionskodierungen f√∂rdern die L√§ngengeneralisierung von Transformatoren. Anian Ruoss (DeepMind) et al. arXiv. [ Papier ] [ Code ]
[2023-03] CoLT5: Schnellere Ferntransformatoren mit bedingter Berechnung. Joshua Ainslie (Google Research) et al. arXiv. [ Papier ]
[2022/03] Effiziente Klassifizierung langer Dokumente mithilfe von Transformern. Hyunji Hayley Park (Illinois University) et al. arXiv. [ Papier ] [ Code ]
[2021/12] LongT5: Effizienter Text-zu-Text-Transformer f√ºr lange Sequenzen. Mandy Guo (Google Research) et al. arXiv. [ Papier ] [ Code ]
[2019/10] BART: Denoising Sequence-to-Sequence Pre-Training f√ºr die Erzeugung, √úbersetzung und das Verst√§ndnis nat√ºrlicher Sprache. Michael Lewis (Facebook AI) et al. arXiv. [ Papier ] [ Code ]
Erinnerung zusammenfassen
[2023/10] Durch das Ged√§chtnislabyrinth: √úber Kontextgrenzen hinaus durch interaktives Lesen Howard Chen (Princeton University) et al. arXiv. [ Papier ]
[2023/09] St√§rkung des Privatunterrichts durch Verkettung gro√üer Sprachmodelle Yulin Chen (Tsinghua-Universit√§t) et al. arXiv. [ Papier ]
[2023/08] ExpeL: LLM-Agenten sind erfahrungsorientierte Lernende. Andrew Zhao (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/08] ChatEval: Auf dem Weg zu besseren LLM-basierten Evaluatoren durch Multi-Agent-Debatte. Chi-Min Chan (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/05] MemoryBank: Erweiterung gro√üer Sprachmodelle mit Langzeitged√§chtnis. Wanjun Zhong (Harbin Institute of Technology) et al. arXiv. [ Papier ] [ Code ]
[2023/04] Generative Agenten: Interaktive Simulakren menschlichen Verhaltens. Joon Sung Park (Stanford University) et al. arXiv. [ Papier ] [ Code ]
[2023/04] Entfesselung der Eingabekapazit√§t unendlicher L√§nge f√ºr gro√üe Sprachmodelle mit selbstkontrolliertem Speichersystem. Xinnian Liang (Universit√§t Beihang) et al. arXiv. [ Papier ] [ Code ]
[2023/03] Reflexion: Sprachagenten mit verbalem Verst√§rkungslernen. Noah Shinn (Northeastern University) et al. arXiv. [ Papier ] [ Code ]
[2023/05] RecurrentGPT: Interaktive Generierung von (beliebig) langem Text. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
Komprimieren von Speichern mit Vektoren oder Datenstrukturen
[2023/07] Kommunikative Agenten f√ºr die Softwareentwicklung. Chen Qian (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/06] ChatDB: Erweiterung von LLMs mit Datenbanken als symbolischem Ged√§chtnis. Chenxu Hu (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Ghost in the Minecraft: Generell leistungsf√§hige Agenten f√ºr Open-World-Umgebungen √ºber gro√üe Sprachmodelle mit textbasiertem Wissen und Ged√§chtnis. Xizhou Zhu (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/05] RET-LLM: Auf dem Weg zu einem allgemeinen Lese-/Schreibspeicher f√ºr gro√üe Sprachmodelle. Ali Modarressi (LMU M√ºnchen) et al. arXiv. [ Papier ] [ Code ]
[2023/05] RecurrentGPT: Interaktive Generierung von (beliebig) langem Text. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
Erinnerungsabruf
[2023/08] Memory Sandbox: Transparente und interaktive Speicherverwaltung f√ºr Konversationsagenten. Ziheng Huang (University of California ‚Äì San Diego) et al. arXiv. [ Papier ]
[2023/08] AgentSims: Eine Open-Source-Sandbox f√ºr die Evaluierung gro√üer Sprachmodelle. Jiaju Lin (PTA Studio) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/06] ChatDB: Erweiterung von LLMs mit Datenbanken als symbolischem Ged√§chtnis. Chenxu Hu (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/05] MemoryBank: Erweiterung gro√üer Sprachmodelle mit Langzeitged√§chtnis. Wanjun Zhong (Harbin Institute of Technology) et al. arXiv. [ Papier ] [ Code ]
[2023/04] Generative Agenten: Interaktive Simulakren menschlichen Verhaltens. Joon Sung Park (Stanford) et al. arXiv. [ Papier ] [ Code ]
[2023/05] RecurrentGPT: Interaktive Generierung von (beliebig) langem Text. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
1.1.4 Argumentation und Planung
Argumentation
[2023/09] ReConcile: Round-Table-Konferenz verbessert die Argumentation durch Konsens zwischen verschiedenen LLMs. Justin Chih-Yao Chen (University of North Carolina at Chapel Hill) et al. arXiv. [ Papier ] [ Code ]

[2023/05] Self-Polish: Verbessern Sie das Denken in gro√üen Sprachmodellen durch Problemverfeinerung. Zhiheng Xi (Fudan-Universit√§t) et al. arXiv. [ Papier ] [ Code ]

[2023-03] Gro√üe Sprachmodelle sind Zero-Shot-Reasonatoren. Takeshi Kojima (Universit√§t Tokio) et al. arXiv. [ Papier ] [ Code ]

[2023/03] Self-Refine: Iterative Verfeinerung mit Selbst-Feedback. Aman Madaan (Carnegie Mellon University) et al. arXiv. [ Papier ] [ Code ]

[2022/05] Auswahl-Inferenz: Nutzung gro√üer Sprachmodelle f√ºr interpretierbares logisches Denken. Antonia Creswell (DeepMind) et al. arXiv. [ Papier ]

[2022/03] Selbstkonsistenz verbessert die Gedankenkette in Sprachmodellen. Xuezhi Wang (Google Research) et al. arXiv. [ Papier ] [ Code ]

[2023/02] Multimodales Chain-of-Thought Reasoning in Sprachmodellen. Zhuosheng Zhang (Shanghai Jiao Tong Universit√§t) et al. arXiv. [ Papier ] [ Code ]

[2022/01] Chain-of-Thought-Prompting l√∂st Argumentation in gro√üen Sprachmodellen aus. Jason Wei (Google Research) et al. arXiv. [ Papier ]

Planung
Planformulierung
[2023/11] JARVIS-1: Open-World-Multitasking-Agenten mit speichererweiterten multimodalen Sprachmodellen. ZiHao Wang (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2023/10] Die Sprachagentenbaumsuche vereint Argumentation, Handeln und Planen in Sprachmodellen. Andy Zhou (University of Illinois Urbana-Champaign) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/05] Gedankenbaum: Bewusste Probleml√∂sung mit gro√üen Sprachmodellen. Shunyu Yao (Princeton University) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Planen, eliminieren und verfolgen ‚Äì Sprachmodelle sind gute Lehrer f√ºr verk√∂rperte Agenten. Yue Wu (Carnegie Mellon University) et al. arXiv. [ Papier ]
[2023/05] Denken mit dem Sprachmodell ist Planen mit dem Weltmodell. Shibo Hao (UC San Diego) et al. arXiv. [ Papier ] [ Code ]
[2023/05] SwiftSage: Ein generativer Agent mit schnellem und langsamem Denken f√ºr komplexe interaktive Aufgaben. Bill Yuchen Lin (Allen Institute for Artificial Intelligence) et al. arXiv. [ Papier ] [ Code ]
[2023/04] LLM+P: Unterst√ºtzung gro√üer Sprachmodelle durch optimale Planungskompetenz. Bo Liu (University of Texas at Austin) et al. arXiv. [ Papier ] [ Code ]
[2023/03] HuggingGPT: KI-Aufgaben l√∂sen mit ChatGPT und seinen Freunden in Hugging Face. Yongliang Shen (Microsoft Research Asia) et al. arXiv. [ Papier ] [ Code ]
[2023/02] Beschreiben, erkl√§ren, planen und ausw√§hlen: Interaktive Planung mit gro√üen Sprachmodellen erm√∂glicht Open-World-Multitasking-Agenten. ZiHao Wang (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2022/05] Least-to-Most-Prompting erm√∂glicht komplexes Denken in gro√üen Sprachmodellen. Denny Zhou (Google Research) et al. arXiv. [ Papier ]
[2022/05] MRKL Systems: Eine modulare, neurosymbolische Architektur, die gro√üe Sprachmodelle, externe Wissensquellen und diskretes Denken kombiniert. Ehud Karpas (AI21 Labs) et al. arXiv. [ Papier ]
[2022/04] Tue, was ich kann, nicht was ich sage: Sprache in Roboterleistungen verankern. Michael Ahn (Robotik bei Google) et al. arXiv. [ Papier ]
[2023/05] Agenten: Ein Open-Source-Framework f√ºr autonome Sprachagenten. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
[2022/12] Nicht generieren, sondern diskriminieren: Ein Vorschlag zur Verankerung von Sprachmodellen in realen Umgebungen. Yu Gu (The Ohio State University) et al. ACL. [ Papier ] [ Code ]
Reflexion planen
[2023/11] JARVIS-1: Open-World-Multitasking-Agenten mit speichererweiterten multimodalen Sprachmodellen. ZiHao Wang (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2023/10] Chain-of-Verification reduziert Halluzinationen in gro√üen Sprachmodellen. Shehzaad Dhuliawala (Meta AI & ETH Z√ºrich) et al. arXiv. [ Papier ]
[2023/10] FireAct: Auf dem Weg zur Feinabstimmung des Sprachagenten. Baian Chen (System2 Research) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Datensatz ]
[2023/08] SelfCheck: Verwenden von LLMs zur Zero-Shot-√úberpr√ºfung ihrer eigenen schrittweisen Argumentation. Ning Miao (Universit√§t Oxford) et al. arXiv. [ Papier ] [ Code ]
[2023/05] ChatCoT: Tool-erweitertes Chain-of-Thought Reasoning auf Chat-basierten gro√üen Sprachmodellen. Zhipeng Chen (Renmin-Universit√§t China) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Voyager: Ein verk√∂rperter Agent mit offenem Ende und gro√üen Sprachmodellen. Guanzhi Wang (NVIDIA) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/03] Chat mit der Umwelt: Interaktive multimodale Wahrnehmung mithilfe gro√üer Sprachmodelle. Xufeng Zhao (Universit√§t Hamburg) et al. arXiv. [ Papier ] [ Code ]
[2022/12] LLM-Planner: Few-Shot Grounded Planning f√ºr verk√∂rperte Agenten mit gro√üen Sprachmodellen. Chan Hee Song (The Ohio State University) et al. arXiv. [ Papier ] [ Code ]
[2022/10] ReAct: Synergie zwischen Denken und Handeln in Sprachmodellen. Shunyu Yao (Princeton University) et al. arXiv. [ Papier ] [ Code ]
[2022/07] Innerer Monolog: Verk√∂rpertes Denken durch Planung mit Sprachmodellen. Wenlong Huang (Robotik bei Google) et al. arXiv. [ Papier ] [ Code ]
[2021/10] KI-Ketten: Transparente und kontrollierbare Mensch-KI-Interaktion durch Verkettung gro√üer Sprachmodell-Eingabeaufforderungen. Tongshuang Wu (University of Washington) et al. arXiv. [ Papier ]
1.1.5 √úbertragbarkeit und Verallgemeinerung
Ungesehene Aufgabenverallgemeinerung
[2023/10] AgentTuning: Aktivierung allgemeiner Agentenf√§higkeiten f√ºr LLMs. Aohan Zeng (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Datensatz ]
[2023/10] Lemur: Harmonisierung nat√ºrlicher Sprache und Code f√ºr Sprachagenten Yiheng Xu (Universit√§t Hongkong) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Sprachmodelle trainieren, um Anweisungen mit menschlichem Feedback zu befolgen. Long Ouyang et al. NeurIPS. [ Papier ]
InstructGPT: Ausrichtung von Sprachmodellen auf die Benutzerabsicht bei einer Vielzahl von Aufgaben durch Feinabstimmung mit menschlichem Feedback.
[2023/01] Multitasking-gest√ºtztes Training erm√∂glicht die Verallgemeinerung von Zero-Shot-Aufgaben. Victor Sanh et al. ICLR. [ Papier ] [ Code ]
T0: T0 ist ein Encoder-Decoder-Modell, das Texteingaben verarbeitet und Zielantworten erzeugt. Es wird auf einer Multitasking-Mischung aus NLP-Datens√§tzen trainiert, die in verschiedene Aufgaben unterteilt sind.
[2022/10] Skalierung von anweisungsfein abgestimmten Sprachmodellen. Hyung Won Chung et al. arXiv. [ Papier ] [ Code ]
Diese Arbeit untersucht die Feinabstimmung von Anweisungen mit besonderem Schwerpunkt auf der Skalierung der Anzahl der Aufgaben und der Modellgr√∂√üe, wodurch die Leistung bei einer Vielzahl von Modellklassen, Eingabeaufforderungseinstellungen und Bewertungsbenchmarks verbessert wird.
[2022/08] Fein abgestimmte Sprachmodelle sind Zero-Shot-Lernende. Jason Wei et al. ICLR. [ Papier ]
FLAN: Die Befehlsoptimierung verbessert die Zero-Shot-Leistung bei unsichtbaren Aufgaben erheblich.
Lernen im Kontext
[2023/08] Bilder sprechen in Bildern: Ein generalistischer Maler f√ºr kontextbezogenes visuelles Lernen. Xinlong Wang et al. IEEE. [ Papier ] [ Code ]
Maler: Diese Arbeit stellt ein generalistisches Modell f√ºr kontextbezogenes visuelles Lernen mit einer ‚Äûbildzentrierten‚Äú L√∂sung vor.
[2023/08] Neuronale Codec-Sprachmodelle sind Zero-Shot-Text-zu-Sprache-Synthesizer. Chengyi Wang et al. arXiv. [ Papier ] [ Code ]
VALL-E: Diese Arbeit trainiert ein neuronales Codec-Sprachmodell, das kontextbezogene Lernf√§higkeiten hervorbringt.
[2023/07] Eine Umfrage zum kontextbezogenen Lernen. Qingxiu Dong et al. arXiv. [ Papier ]
Diese Umfrage fasst die Fortschritte und Herausforderungen des In-Context-Lernens (ICL) zusammen.
[2023/05] Sprachmodelle sind Few-Shot-Lernende. Tom B. Brown (OpenAI) et al. NeurIPS. [ Papier ]
GPT-3: Die Skalierung von Sprachmodellen verbessert die aufgabenunabh√§ngige Leistung bei wenigen Sch√ºssen erheblich und wird manchmal sogar mit fr√ºheren Feinabstimmungsans√§tzen auf dem neuesten Stand der Technik konkurrenzf√§hig.
Kontinuierliches Lernen
[2023/11] JARVIS-1: Open-World-Multitasking-Agenten mit speichererweiterten multimodalen Sprachmodellen. ZiHao Wang (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2023/07] Progressive Prompts: Kontinuierliches Lernen f√ºr Sprachmodelle. Razdaibiedina et al. arXiv. [ Papier ]
In dieser Arbeit werden progressive Eingabeaufforderungen vorgestellt, die eine Vorw√§rts√ºbertragung erm√∂glichen und katastrophalem Vergessen widerstehen, ohne auf die Datenwiedergabe oder eine gro√üe Anzahl aufgabenspezifischer Parameter angewiesen zu sein.
[2023/05] Voyager: Ein verk√∂rperter Agent mit offenem Ende und gro√üen Sprachmodellen. Guanzhi Wang (NVIDIA) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
Voyager: Dies ist ein Beispiel f√ºr einen LLM-gest√ºtzten, verk√∂rperten lebenslangen Lernagenten in Minecraft, der kontinuierlich die Welt erkundet, verschiedene F√§higkeiten erwirbt und ohne menschliches Eingreifen neue Entdeckungen macht.
[2023/01] Ein umfassender √úberblick √ºber kontinuierliches Lernen: Theorie, Methode und Anwendung. Liyuan Wang et al. arXiv. [ Papier ]
Diese Umfrage stellt einen umfassenden √úberblick √ºber kontinuierliches Lernen dar und versucht, eine Br√ºcke zwischen grundlegenden Einstellungen, theoretischen Grundlagen, repr√§sentativen Methoden und praktischen Anwendungen zu schlagen.
[2022/11] Kontinuierliches Lernen von Aufgaben zur Verarbeitung nat√ºrlicher Sprache: Eine Umfrage. Zixuan Ke et al. arXiv. [ Papier ]
Diese Umfrage bietet einen umfassenden √úberblick und eine Analyse der j√ºngsten Fortschritte von CL im NLP.
1.2 Wahrnehmung: Multimodale Eingaben f√ºr LLM-basierte Agenten
1.2.1 Visuell
[2023/10] Auf dem Weg zu einer durchg√§ngigen verk√∂rperten Entscheidungsfindung √ºber ein multimodales gro√ües Sprachmodell: Erkundungen mit GPT4-Vision und dar√ºber hinaus Liang Chen et al. arXiv. [ Papier ] [ Code ]
[2023/05] Sprache ist nicht alles, was Sie brauchen: Wahrnehmung mit Sprachmodellen in Einklang bringen. Shaohan Huang et al. arXiv. [ Papier ]
[2023/05] InstructBLIP: Auf dem Weg zu universellen Vision-Language-Modellen mit Instruction Tuning. Wenliang Dai et al. arXiv. [ Papier ]
[2023/05] MultiModal-GPT: Ein Visions- und Sprachmodell f√ºr den Dialog mit Menschen. Tao Gong et al. arXiv. [ Papier ]
[2023/05] PandaGPT: Ein Modell zum Anleiten ‚Äì Befolgen Sie sie alle. Yixuan Su et al. arXiv. [ Papier ]
[2023/04] Optimierung der visuellen Anweisungen. Haotian Liu et al. arXiv. [ Papier ]
[2023/04] MiniGPT-4: Verbesserung des Vision-Sprach-Verst√§ndnisses mit fortschrittlichen gro√üen Sprachmodellen. Deyao Zhu. arXiv. [ Papier ]
[2023/01] BLIP-2: Bootstrapping-Sprachbild-Vortraining mit Encodern f√ºr eingefrorene Bilder und gro√üen Sprachmodellen. Junnan Li et al. arXiv. [ Papier ]
[2022/04] Flamingo: ein visuelles Sprachmodell f√ºr Few-Shot-Lernen. Jean-Baptiste Alayrac et al. arXiv. [ Papier ]
[2021/10] MobileViT: Leichter, universeller und mobilfreundlicher Vision Transformer. Sachin Mehta et al.arXiv. [ Papier ]
[2021/05] MLP-Mixer: Eine reine MLP-Architektur f√ºr Vision. Ilya Tolstikhin et al.arXiv. [ Papier ]
[2020/10] Ein Bild sagt mehr als 16 x 16 Worte: Transformatoren f√ºr die Bilderkennung im Ma√üstab. Alexey Dosovitskiy et al. arXiv. [ Papier ]
[2017/11] Neuronales diskretes Repr√§sentationslernen. Aaron van den Oord et al. arXiv. [ Papier ]
1.2.2 Audio
[2023/06] Video-LLaMA: Ein auf Anweisungen abgestimmtes audiovisuelles Sprachmodell f√ºr das Videoverst√§ndnis. Hang Zhang et al. arXiv. [ Papier ]
[2023/05] X-LLM: Bootstrapping fortgeschrittener gro√üer Sprachmodelle durch Behandlung von Multimodalit√§ten als Fremdsprachen. Feilong Chen et al. arXiv. [ Papier ]
[2023/05] InternGPT: Vision-zentrierte Aufgaben durch Interaktion mit ChatGPT Beyond Language l√∂sen. Zhaoyang Liu et al. arXiv. [ Papier ]
[2023/04] AudioGPT: Sprache, Musik, Ton und sprechenden Kopf verstehen und erzeugen. Rongjie Huang et al. arXiv. [ Papier ]
[2023/03] HuggingGPT: KI-Aufgaben l√∂sen mit ChatGPT und seinen Freunden in Hugging Face. Yongliang Shen et al. arXiv. [ Papier ]
[2021/06] HuBERT: Selbst√ºberwachtes Sprachrepr√§sentationslernen durch maskierte Vorhersage versteckter Einheiten. Wei-Ning Hsu et al. arXiv. [ Papier ]
[2021/04] AST: Audio Spectrogram Transformer. Yuan Gong et al. arXiv. [ Papier ]
1.3 Aktion: Aktionsraum von LLM-basierten Agenten erweitern
1.3.1 Werkzeugverwendung
[2023/10] OpenAgents: Eine offene Plattform f√ºr Sprachagenten in freier Wildbahn. XLang Lab (Universit√§t Hongkong) arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Demo ]
[2023/10] Lemur: Harmonisierung nat√ºrlicher Sprache und Code f√ºr Sprachagenten Yiheng Xu (Universit√§t Hongkong) et al. arXiv. [ Papier ] [ Code ]
[2023/10] Auf dem Weg zu einer durchg√§ngigen verk√∂rperten Entscheidungsfindung √ºber ein multimodales gro√ües Sprachmodell: Erkundungen mit GPT4-Vision und dar√ºber hinaus Liang Chen (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
HOLMES ist ein Multi-Agenten-Kooperationsrahmen, der es LLMs erm√∂glicht, MLLMs und APIs zu nutzen, um multimodale Informationen f√ºr eine fundierte Entscheidungsfindung zu sammeln.
[2023/07] ToolLLM: Erleichtert die Beherrschung gro√üer Sprachmodelle von √ºber 16.000 realen APIs. Yujia Qin (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ] [ Datensatz ]
ToolLLM ist ein allgemeines Tool-Nutzungs-Framework, das Datenkonstruktion, Modelltraining und -bewertung umfasst.
[2023/05] Gro√üe Sprachmodelle als Werkzeugmacher. Tianle Cai (Princeton University) et al. arXiv. [ Papier ] [ Code ]
LATM ist ein Closed-Loop-Framework, das einen ersten Schritt zur Beseitigung der Abh√§ngigkeit von der Verf√ºgbarkeit vorhandener Tools unternimmt.
[2023/05] CREATOR: Abstrakte und konkrete √úberlegungen gro√üer Sprachmodelle durch Tool-Erstellung entwirren. Cheng Qian (Tsinghua-Universit√§t) et al. arXiv. [ Papier ]
CREATOR ist ein neuartiges Framework, das es LLMs erm√∂glicht, ihre eigenen Tools durch Dokumentation und Code-Realisierung zu erstellen.
[2023/04] Tool-Lernen mit Grundlagenmodellen. Yujia Qin (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
Diese Umfrage stellt in erster Linie ein neues Paradigma namens ‚ÄûTool-Lernen auf Basis grundlegender Modelle‚Äú vor, das die Vorteile spezialisierter Tools und grundlegender Modelle kombiniert und so eine h√∂here Pr√§zision, Effizienz und Automatisierung bei der Probleml√∂sung erreicht.
[2023/04] ChemCrow: Erweiterung gro√üer Sprachmodelle mit Chemie-Tools. Andres M Bran (Labor f√ºr k√ºnstliche chemische Intelligenz, ISIC, EPFL) et al. arXiv. [ Papier ] [ Code ]
ChemCrow ist ein LLM-Chemieagent, der 13 von Experten entwickelte Tools integriert, die LLM-Leistung in der Chemie steigert und neue F√§higkeiten hervorbringt.
[2023/04] GeneGPT: Erweiterung gro√üer Sprachmodelle mit Dom√§nentools f√ºr einen verbesserten Zugang zu biomedizinischen Informationen. Qiao Jin (National Institutes of Health), Yifan Yang, Qingyu Chen, Zhiyong Lu. arXiv. [ Papier ] [ Code ]
GeneGPT ist ein Modell, das Fragen zur Genomik beantwortet. Es stellt eine neuartige Methode zur Bew√§ltigung von Herausforderungen mit Halluzinationen vor, indem LLMs die Verwendung der Web-APIs beigebracht werden.
[2023/04] OpenAGI: Wenn LLM Dom√§nenexperten trifft. Yingqiang Ge (Rutgers University) et al. arXiv. [ Papier ] [ Code ]
OpenAGI ist eine Open-Source-AGI-Forschungsplattform. Es stellt ein Paradigma f√ºr LLMs vor, die verschiedene Expertenmodelle zur L√∂sung komplexer Aufgaben betreiben, und schl√§gt einen RLTF-Mechanismus vor, um die F√§higkeit des LLM zur Aufgabenl√∂sung zu verbessern.
[2023/03] HuggingGPT: KI-Aufgaben l√∂sen mit ChatGPT und seinen Freunden in Hugging Face. Yongliang Shen (Universit√§t Zhejiang) et al. arXiv. [ Papier ] [ Code ]
HuggingGPT ist ein System, das LLMs nutzt, um verschiedene und multimodale KI-Modelle in Communitys f√ºr maschinelles Lernen zu verbinden und so KI-Aufgaben zu l√∂sen.
[2023/03] Visual ChatGPT: Sprechen, Zeichnen und Bearbeiten mit Visual Foundation-Modellen. Chenfei Wu (Microsoft Research Asia) et al. arXiv. [ Papier ] [ Code ]
Visual ChatGPT ist ein System, das die T√ºr zur Untersuchung der visuellen Rollen von ChatGPT mithilfe von Visual Foundation Models √∂ffnet.
[2023/02] Augmented Language Models: eine Umfrage. Gr√©goire Mialon (Meta AI) et al. TMLR. [ Papier ]
In dieser Umfrage werden Arbeiten √ºberpr√ºft, bei denen LMs um die F√§higkeit erweitert werden, Werkzeuge zu verwenden. Erweiterte LMs k√∂nnen externe Module verwenden, um ihre Kontextverarbeitungsf√§higkeiten zu erweitern.
[2023/02] Toolformer: Sprachmodelle k√∂nnen sich selbst den Umgang mit Werkzeugen beibringen. Timo Schick (Meta AI) et al. arXiv. [ Papier ]
Toolformer zeigt anhand einer Handvoll Demonstrationen f√ºr jede API, dass LLMs sich selbst beibringen k√∂nnen, externe Tools zu verwenden.
[2022/05] TALM: Tool Augmented Language Models. Aaron Parisi (Google) et al. arXiv. [ Papier ]
TALM f√ºhrt eine Methode ein, die nicht differenzierbare Tools mit LMs kombiniert und es dem Modell erm√∂glicht, auf Echtzeit- oder private Daten zuzugreifen.
[2022/05] MRKL Systems: Eine modulare, neurosymbolische Architektur, die gro√üe Sprachmodelle, externe Wissensquellen und diskretes Denken kombiniert. Ehud Karpas (AI21 Labs) et al. arXiv. [ Papier ]
MRKL Systems erweitert LLMs durch einen leicht erweiterbaren Satz externer Wissens- und Argumentationsmodule.
[2022/04] Tue, was ich kann, nicht was ich sage: Sprache in Roboterleistungen verankern. Michael Ahn (Google) et al. CoRL. [ Papier ]
SayCan wendet LMs in realen Roboteraufgaben an, indem es fortgeschrittenes semantisches Wissen von LLMs mit der Wertfunktion vorab trainierter F√§higkeiten kombiniert.
[2021/12] WebGPT: Browsergest√ºtzte Fragebeantwortung mit menschlichem Feedback. Reiichiro Nakano (OpenAI) et al. arXiv. [ Papier ]
WebGPT beantwortet Fragen mithilfe einer Webbrowser-Umgebung. Es nutzt Nachahmungslernen w√§hrend des Trainings und optimiert dann die Antwortqualit√§t durch menschliches Feedback.
[2021/07] Evaluierung gro√üer Sprachmodelle, die auf Code trainiert wurden. Mark Chen (OpenAI) et al. arXiv. [ Papier ] [ Code ]
Codex kann Programme aus Dokumentzeichenfolgen synthetisieren, d. h. Tools basierend auf der Dokumentation erstellen.
1.3.2 Verk√∂rperte Aktion
[2023/11] Ein verk√∂rperter generalistischer Agent in der 3D-Welt. Jiangyong Huang (BIGAI & Peking University) et al. arXiv. [ Papier ] [ Projektseite ]
[2023/11] JARVIS-1: Open-World-Multitasking-Agenten mit speichererweiterten multimodalen Sprachmodellen. ZiHao Wang (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2023/10] Lemur: Harmonisierung nat√ºrlicher Sprache und Code f√ºr Sprachagenten Yiheng Xu (Universit√§t Hongkong) et al. arXiv. [ Papier ] [ Code ]
[2023/10] Auf dem Weg zu einer durchg√§ngigen verk√∂rperten Entscheidungsfindung √ºber ein multimodales gro√ües Sprachmodell: Erkundungen mit GPT4-Vision und dar√ºber hinaus Liang Chen et al. arXiv. [ Papier ] [ Code ]
[2023/07] Interaktive Sprache: In Echtzeit mit Robotern sprechen. Corey Lynch et al. IEEE (RAL) [ Papier ]
[2023/05] Voyager: Ein verk√∂rperter Agent mit offenem Ende und gro√üen Sprachmodellen. Guanzhi Wang (NVIDIA) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/05] AVLEN: Audio-visuell-sprachliche verk√∂rperte Navigation in 3D-Umgebungen. Sudipta Paul et al. NeurIPS. [ Papier ]
[2023/05] EmbodiedGPT: Vision-Language-Vorschulung √ºber die verk√∂rperte Gedankenkette. Yao Mu et al. Arxiv [ Papier ] [ Code ]
[2023/05] NavGPT: Explizites Denken in der Vision-and-Language-Navigation mit gro√üen Sprachmodellen. Gengze Zhou et al. Arxiv [ Papier ]
[2023/05] AlphaBlock: Verk√∂rperte Feinabstimmung f√ºr Vision-Language Reasoning in der Robotermanipulation. Chuhao Jin et al. Arxiv [ Papier ]
[2023/03] PaLM-E: Ein verk√∂rpertes multimodales Sprachmodell. Danny Driess et al. Arxiv. [ Papier ]
[2023/03] Reflexion: Sprachagenten mit verbalem Verst√§rkungslernen. Noah Shinn et al. Arxiv [ Papier ] [ Code ]
[2023/02] Zusammenarbeit mit Sprachmodellen f√ºr verk√∂rpertes Denken. Ishita Dasgupta et al. Arxiv. [ Papier ]
[2023/02] Code als Richtlinien: Sprachmodellprogramme f√ºr verk√∂rperte Kontrolle. Jacky Liang et al. IEEE (ICRA). [ Papier ]
[2022/10] ReAct: Synergie zwischen Denken und Handeln in Sprachmodellen. Shunyu Yao et al. Arxiv [ Papier ] [ Code ]
[2022/10] Befehlsfolgende Agenten mit multimodalem Transformator. Hao Liu et al. CVPR [ Papier ] [ Code ]
[2022/07] Innerer Monolog: Verk√∂rpertes Denken durch Planung mit Sprachmodellen. Wenlong Huang et al. Arxiv. [ Papier ]
[2022/07] LM-Nav: Roboternavigation mit gro√üen vortrainierten Modellen f√ºr Sprache, Vision und Aktion. Dhruv Shahet al. CoRL [ Papier ] [ Code ]
[2022/04] Tue, was ich kann, nicht was ich sage: Sprache in Roboterleistungen verankern. Michael Ahn et al. Arxiv. [ Papier ]
[2022/01] Ein √úberblick √ºber verk√∂rperte KI: Von Simulatoren zu Forschungsaufgaben. Jiafei Duan et al. IEEE (TETCI). [ Papier ]
[2022/01] Sprachmodelle als Zero-Shot-Planer: Extrahieren von umsetzbarem Wissen f√ºr verk√∂rperte Agenten. Wenlong Huang et al. Arxiv. [ Papier ] [ Code ]
[2020/04] Experience Grounds Language. Yonatan Bisk et al. EMNLP [ Papier ]
[2019/03] R√ºckblick auf Deep Reinforcement Learning zur Robotermanipulation. Hai Nguyen et al. IEEE (IRC). [ Papier ]
[2005/01] Die Entwicklung der verk√∂rperten Kognition: Sechs Lektionen von Babys. Linda Smith et al. K√ºnstliches Leben. [ Papier ]
2. Agenten in der Praxis: Anwendungen von LLM-basierten Agenten

2.1 Allgemeine F√§higkeiten eines Einzelagenten

2.1.1 Aufgabenorientierte Bereitstellung
In Webszenarien

[2023/10] OpenAgents: Eine offene Plattform f√ºr Sprachagenten in freier Wildbahn. XLang Lab (Universit√§t Hongkong) arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Demo ]
[2023/07] WebArena: Eine realistische Webumgebung zum Aufbau autonomer Agenten. Shuyan Zhou (CMU) et al. arXiv. [ Papier ] [ Code ]
[2023/07] Ein realer WebAgent mit Planung, umfassendem Kontextverst√§ndnis und Programmsynthese. Izzeddin Gur (DeepMind) et al. arXiv. [ Papier ]
[2023/06] SYNAPSE: Nutzung von Few-Shot-Exemplaren f√ºr die Computersteuerung auf menschlicher Ebene. Longtao Zheng (Nanyang Technological University) et al. arXiv. [ Papier ] [ Code ]
[2023/06] Mind2Web: Auf dem Weg zu einem generalistischen Agenten f√ºr das Web. Xiang Deng (Ohio State University) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Multimodale Webnavigation mit durch Anweisungen abgestimmten Grundlagenmodellen. Hiroki Furuta (Universit√§t Tokio) et al. arXiv. [ Papier ]
[2023/03] Sprachmodelle k√∂nnen Computeraufgaben l√∂sen. Geunwoo Kim (University of California) et al. arXiv. [ Papier ] [ Code ]
[2022/07] WebShop: Auf dem Weg zu einer skalierbaren realen Webinteraktion mit Grounded Language Agents. Shunyu Yao (Princeton University) et al. arXiv. [ Papier ] [ Code ]
[2021/12] WebGPT: Browsergest√ºtzte Fragebeantwortung mit menschlichem Feedback. Reiichiro Nakano (OpenAI) et al. arXiv. [ Papier ]
[2023/05] Agenten: Ein Open-Source-Framework f√ºr autonome Sprachagenten. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
In Lebensszenarien

[2023/10] OpenAgents: Eine offene Plattform f√ºr Sprachagenten in freier Wildbahn. XLang Lab (Universit√§t Hongkong) arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Demo ]
[2023/08] InterAct: Erkundung der Potenziale von ChatGPT als kooperativer Agent. Po-Lin Chen et al. arXiv. [ Papier ]
[2023/05] Planen, eliminieren und verfolgen ‚Äì Sprachmodelle sind gute Lehrer f√ºr verk√∂rperte Agenten. Yue Wu (CMU) et al. arXiv. [ Papier ]
[2023/05] Erweiterung autotelischer Agenten mit gro√üen Sprachmodellen. C√©dric Colas (MIT) et al. arXiv. [ Papier ]
[2023/03] Planung mit gro√üen Sprachmodellen durch korrigierendes Re-Prompting. Shreyas Sundara Raman (Brown University) et al. arXiv. [ Papier ]
[2022/10] Generierung ausf√ºhrbarer Aktionspl√§ne mit umweltbewussten Sprachmodellen. Maitrey Gramopadhye (University of North Carolina at Chapel Hill) et al. arXiv. [ Papier ] [ Code ]
[2022/01] Sprachmodelle als Zero-Shot-Planer: Extrahieren von umsetzbarem Wissen f√ºr verk√∂rperte Agenten. Wenlong Huang (UC Berkeley) et al. arXiv. [ Papier ] [ Code ]
2.1.2 Innovationsorientierter Einsatz
[2023/10] OpenAgents: Eine offene Plattform f√ºr Sprachagenten in freier Wildbahn. XLang Lab (Universit√§t Hongkong) arXiv. [ Papier ] [ Projektseite ] [ Code ] [ Demo ]
[2023/08] Per Anhalter zur Programmanalyse: Eine Reise mit gro√üen Sprachmodellen. Haonan Li (UC Riverside) et al. arXiv. [ Papier ]
[2023/08] ChatMOF: Ein autonomes KI-System zur Vorhersage und Generierung metallorganischer Ger√ºste. Yeonghun Kang (Korea Advanced Institute of Science and Technology) et al. arXiv. [ Papier ]
[2023/07] Mathe-Agenten: Computerinfrastruktur, mathematische Einbettung und Genomik. Melanie Swan (University College London) et al. arXiv. [ Papier ]
[2023/06] Auf dem Weg zu autonomen Testagenten √ºber konversationale gro√üe Sprachmodelle. Robert Feldt (Chalmers University of Technology) et al. arXiv. [ Papier ]
[2023/04] Neue autonome wissenschaftliche Forschungsf√§higkeiten gro√üer Sprachmodelle. Daniil A. Boiko (CMU) et al. arXiv. [ Papier ]
[2023/04] ChemCrow: Erweiterung gro√üer Sprachmodelle mit Chemie-Tools. Andres M Bran (Labor f√ºr k√ºnstliche chemische Intelligenz, ISIC, EPFL) et al. arXiv. [ Papier ] [ Code ]
[2022/03] ScienceWorld: Ist Ihr Agent schlauer als ein F√ºnftkl√§ssler? Ruoyao Wang (Universit√§t von Arizona) et al. arXiv. [ Papier ] [ Code ]
2.1.3 Lebenszyklusorientierte Bereitstellung
[2023/05] Voyager: Ein verk√∂rperter Agent mit offenem Ende und gro√üen Sprachmodellen. Guanzhi Wang (NVIDIA) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/05] Ghost in the Minecraft: Generell leistungsf√§hige Agenten f√ºr Open-World-Umgebungen √ºber gro√üe Sprachmodelle mit textbasiertem Wissen und Ged√§chtnis. Xizhou Zhu (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/03] Plan4MC: Lernen und Planen zur Kompetenzverst√§rkung f√ºr Open-World-Minecraft-Aufgaben. Haoqi Yuan (PKU) et al. arXiv. [ Papier ] [ Projektseite ]
[2023/02] Beschreiben, erkl√§ren, planen und ausw√§hlen: Interaktive Planung mit gro√üen Sprachmodellen erm√∂glicht Open-World-Multitasking-Agenten. Zihao Wang (PKU) et al. arXiv. [ Papier ] [ Code ]
[2023/01] Tr√§umen verk√∂rperte Agenten von pixeligen Schafen: Verk√∂rperte Entscheidungsfindung mithilfe sprachgesteuerter Weltmodellierung. Kolby Nottingham (University of California Irvine, Irvine) et al. arXiv. [ Papier ] [ Code ]
2.2 Koordinierungspotential mehrerer Agenten

2.2.1 Kooperative Interaktion f√ºr Komplementarit√§t
Ungeordnete Zusammenarbeit

[2023/07] Freisetzung kognitiver Synergien in gro√üen Sprachmodellen: Ein Agent zur Aufgabenl√∂sung durch Selbstzusammenarbeit mehrerer Personen. Zhenhailong Wang (University of Illinois Urbana-Champaign) et al. arXiv. [ Papier ] [ Code ]
[2023/07] RoCo: Dialektische Multi-Roboter-Kollaboration mit gro√üen Sprachmodellen. Zhao Mandi, Shreeya Jain, Shuran Song (Columbia University) et al. arXiv. [ Papier ] [ Code ]
[2023/04] ChatLLM-Netzwerk: Mehr Gehirne, mehr Intelligenz. Rui Hao (Universit√§t f√ºr Post und Telekommunikation Peking) et al. arXiv. [ Papier ]
[2023/01] Blindes Urteil: Agentenbasierte Modellierung des Obersten Gerichtshofs mit GPT. Sil Hamilton (McGill University). arXiv. [ Papier ]
[2023/05] Agenten: Ein Open-Source-Framework f√ºr autonome Sprachagenten. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
Geordnete Zusammenarbeit

[2023/10] AutoAgents: Ein Framework f√ºr die automatische Agentengenerierung. Guangyao Chen (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2023/09] MindAgent: Neue Gaming-Interaktion. Ran Gong (UCLA) et al. arXiv. [ Papier ] [ Code ]
[2023/08] CGMI: Konfigurierbares allgemeines Multi-Agent-Interaktions-Framework. Shi Jinxin (East China Normal University) et al. arXiv. [ Papier ]
[2023/08] ProAgent: Aufbau einer proaktiven kooperativen KI mit gro√üen Sprachmodellen. Ceyao Zhang (Chinesische Universit√§t Hongkong, Shenzhen) et al. arXiv. [ Papier ] [ Code ]
[2023/08] AgentVerse: Erleichterung der Zusammenarbeit mehrerer Agenten und Erforschung neu auftretender Verhaltensweisen bei Agenten. Weize Chen (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/08] AutoGen: Erm√∂glichung von LLM-Anwendungen der n√§chsten Generation √ºber das Multi-Agent Conversation Framework. Qingyun Wu (Pennsylvania State University) et al. arXiv. [ Papier ] [ Code ]
[2023/08] MetaGPT: Metaprogrammierung f√ºr das Multi-Agent Collaborative Framework. Sirui Hong (DeepWisdom) et al. arXiv. [ Papier ] [ Code ]
[2023/07] Kommunikative Agenten f√ºr die Softwareentwicklung. Chen Qian (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/06] Multi-Agenten-Zusammenarbeit: Die Leistungsf√§higkeit intelligenter LLM-Agenten nutzen. Yashar Talebira (Universit√§t Alberta) et al. arXiv. [ Papier ]
[2023/05] Training sozial ausgerichteter Sprachmodelle in der simulierten menschlichen Gesellschaft. Ruibo Liu (Dartmouth College) et al. arXiv. [ Papier ] [ Code ]
[2023/05] SwiftSage: Ein generativer Agent mit schnellem und langsamem Denken f√ºr komplexe interaktive Aufgaben. Bill Yuchen Lin (Allen Institute for Artificial Intelligence) et al. arXiv. [ Papier ] [ Code ]
[2023/05] ChatGPT als Ihr Personal Data Scientist. Md Mahadi Hassan (Auburn University) et al. arXiv. [ Papier ]
[2023/03] CAMEL: Kommunikative Mittel zur ‚ÄûGeistes‚Äú-Erforschung einer gro√ü angelegten Sprachmodellgesellschaft. Guohao Li (King Abdullah University of Science and Technology) et al. arXiv. [ Papier ] [ Code ]
[2023/03] DERA: Verbesserung der Vervollst√§ndigung gro√üer Sprachmodelle mit dialogf√§higen Aufl√∂sungsagenten. Varun Nair (Curai Health) et al. arXiv. [ Papier ] [ Code ]
[2023/04] Selbstkollaborative Codegenerierung √ºber ChatGPT. Yihong Dong (Universit√§t Peking) et al. arXiv. [ Papier ]
2.2.2 Gegnerische Interaktion f√ºr den Fortschritt
[2023/08] ChatEval: Auf dem Weg zu besseren LLM-basierten Evaluatoren durch Multi-Agent-Debatte. Chi-Min Chan (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Verbesserung der Faktizit√§t und Argumentation in Sprachmodellen durch Multiagentendebatte. Yilun Du (MIT CSAIL) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Verbesserung der Sprachmodellverhandlung durch Selbstspiel und kontextbezogenes Lernen aus KI-Feedback. Yao Fu (Universit√§t Edinburgh) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Untersuchung der Interkonsistenz gro√üer Sprachmodelle: Eine eingehende Analyse mittels Debatte. Kai Xiong (Harbin Institute of Technology) et al. arXiv. [ Papier ]
[2023/05] Divergentes Denken in gro√üen Sprachmodellen durch Multi-Agenten-Debatte f√∂rdern. Tian Liang (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
2.3 Interaktive Interaktion zwischen Mensch und Agent

2.3.1 Instructor-Executor-Paradigma
Ausbildung
[2023/07] Mathe-Agenten: Computerinfrastruktur, mathematische Einbettung und Genomik. Melanie Swan (UCL) et al. arXiv. [ Papier ]
Kommunizieren Sie mit Menschen, um ihnen zu helfen, Mathematik zu verstehen und anzuwenden.
[2023/03] Hey Dona! K√∂nnen Sie mir bei der Kursanmeldung f√ºr Studierende helfen? Vishesh Kalvakurthi (MSU) et al. arXiv. [ Papier ]
Hierbei handelt es sich um eine entwickelte Anwendung namens Dona, die virtuelle Sprachunterst√ºtzung bei der Kursanmeldung f√ºr Studierende bietet, bei der Menschen Anweisungen geben.
Gesundheit
[2023/08] Zhongjing: Verbesserung der chinesischen medizinischen F√§higkeiten eines gro√üen Sprachmodells durch Experten-Feedback und realen Multi-Turn-Dialog. Songhua Yang (ZZU) et al. arXiv. [ Papier ] [ Code ]
[2023/05] HuatuoGPT, auf dem Weg, das Sprachmodell zu z√§hmen, um Arzt zu werden. Hongbo Zhang (CUHK-SZ) et al. arXiv. [ Papier ] [ Code ] [ Demo ]
[2023/05] Dem Helfer helfen: Unterst√ºtzung von Peer-Beratern durch KI-gest√ºtzte Praxis und Feedback. Shang-Ling Hsu (Gatech) et al. arXiv. [ Papier ]
[2020/10] Ein virtueller Gespr√§chsagent f√ºr Jugendliche mit Autismus-Spektrum-St√∂rung: Experimentelle Ergebnisse und Design-Lektionen. Mohammad Rafayet Ali (U of R) et al. IVA '20. [ Papier ]
Andere Anwendung
[2023/08] RecMind: Gro√üer Sprachmodell-basierter Agent f√ºr Empfehlungen. Yancheng Wang (ASU, Amazon) et al. arXiv. [ Papier ]
[2023/08] Multi-Turn-Dialogagent als Vertriebsassistent im Telemarketing. Wanting Gao (JNU) et al. IEEE. [ Papier ]
[2023/07] PEER: Ein kollaboratives Sprachmodell. Timo Schick (Meta AI) et al. arXiv. [ Papier ]
[2023/07] DIALGEN: Kollaborative von Mensch und LM generierte Dialoge f√ºr ein besseres Verst√§ndnis von Mensch-Mensch-Gespr√§chen. Bo-Ru Lu (UW) et al. arXiv. [ Papier ]
[2023/06] AssistGPT: Ein allgemeiner multimodaler Assistent, der planen, ausf√ºhren, pr√ºfen und lernen kann. Difei Gao (NUS) et al. arXiv. [ Papier ]
[2023/05] Agenten: Ein Open-Source-Framework f√ºr autonome Sprachagenten. Wangchunshu Zhou (AIWaves) et al. arXiv. [ Papier ] [ Code ]
2.3.2 Paradigma der gleichberechtigten Partnerschaft
Einf√ºhlsamer Kommunikator
[2023/08] SAPIEN: Affektive virtuelle Agenten, die auf gro√üen Sprachmodellen basieren. Masum Hasan et al. arXiv. [ Papier ] [ Projektseite ]
[2023/05] Dem Helfer helfen: Unterst√ºtzung von Peer-Beratern durch KI-gest√ºtzte Praxis und Feedback. Shang-Ling Hsu (Gatech) et al. arXiv. [ Papier ]
[2022/07] K√ºnstliche Empathie in Marketinginteraktionen: √úberbr√ºckung der L√ºcke zwischen Mensch und KI im affektiven und sozialen Kundenerlebnis. Yuping Liu-Thompkins et al. [ Papier ]
Teilnehmer auf menschlicher Ebene
[2023/08] Quantifizierung des Einflusses gro√üer Sprachmodelle auf die kollektive Meinungsdynamik. Chao Li et al. AdR. [ Papier ]
[2023/06] Das Spiel der No-Press-Diplomatie durch vom Menschen reguliertes Verst√§rkungslernen und -planung meistern. Anton Bakhtin et al. ICLR. [ Papier ]
[2023/06] Entscheidungsorientierter Dialog f√ºr die Zusammenarbeit zwischen Mensch und KI. Jessy Lin et al. AdR. [ Papier ]
[2022/11] Spielen auf menschlicher Ebene im Spiel der Diplomatie durch die Kombination von Sprachmodellen mit strategischem Denken. FAIR et al. Wissenschaft. [ Papier ]
3. Agentengesellschaft: Von der Individualit√§t zur Sozialit√§t

3.1 Verhalten und Pers√∂nlichkeit von LLM-basierten Agenten
3.1.1 Sozialverhalten
Individuelle Verhaltensweisen
[2023/10] Lyfe Agents: Generative Agenten f√ºr kosteng√ºnstige soziale Interaktionen in Echtzeit. Zhao Kaiya (MIT) et al. arXiv. [ Papier ]
[2023/05] Voyager: Ein verk√∂rperter Agent mit offenem Ende und gro√üen Sprachmodellen. Guanzhi Wang (NVIDIA) et al. arXiv. [ Papier ] [ Code ] [ Projektseite ]
[2023/04] LLM+P: Unterst√ºtzung gro√üer Sprachmodelle durch optimale Planungskompetenz. Bo Liu (Universit√§t von Texas) et al. arXiv. [ Papier ] [ Code ]
[2023/03] Reflexion: Sprachagenten mit verbalem Verst√§rkungslernen. Noah Shinn (Northeastern University) et al. arXiv. [ Papier ] [ Code ]
[2023/03] PaLM-E: Ein verk√∂rpertes multimodales Sprachmodell. Danny Driess (Google) et al. ICML. [ Papier ] [ Projektseite ]
[2023/03] ReAct: Synergie von Denken und Handeln in Sprachmodellen. Shunyu Yao (Princeton University) et al. ICLR. [ Papier ] [ Projektseite ]
[2022/01] Die Aufforderung zur Gedankenkette l√∂st Argumentation in gro√üen Sprachmodellen aus. Jason Wei (Google) et al. NeurIPS. [ Papier ]
Gruppenverhalten
[2023/10] Erforschung von Kooperationsmechanismen f√ºr LLM-Agenten: Eine sozialpsychologische Sicht. Jintian Zhang (Universit√§t Zhejiang) et al. arXiv. [ Papier ] [ Code ]

[2023/09] MindAgent: Neue Gaming-Interaktion. Ran Gong (UCLA) et al. arXiv. [ Papier ] [ Code ]

[2023/09] Erforschung gro√üer Sprachmodelle f√ºr Kommunikationsspiele: Eine empirische Studie √ºber Werwolf. Yuzhuang Xu (Tsinghua-Universit√§t) et al. arXiv. [ Papier ]

[2023/09] Suspicion Agent: Unvollkommene Informationsspiele mit Theory of Mind Aware spielen GPT-4 Jiaxian Gu oet al. arXiv. [ Papier ]

[2023/08] AgentVerse: Erleichterung der Zusammenarbeit mehrerer Agenten und Erforschung neu auftretender Verhaltensweisen bei Agenten. Weize Chen (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]

[2023/08] AutoGen: Erm√∂glichung von LLM-Anwendungen der n√§chsten Generation √ºber das Multi-Agent Conversation Framework. Qingyun Wu (Pennsylvania State University) et al. arXiv. [ Papier ] [ Code ]

[2023/08] ChatEval: Auf dem Weg zu besseren LLM-basierten Evaluatoren durch Multi-Agent-Debatte. Chi-Min Chan (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]

[2023/07] Kommunikative Agenten f√ºr die Softwareentwicklung. Chen Qian (Tsinghua-Universit√§t) et al. arXiv. [ Papier ] [ Code ]

[2023/07] RoCo: Dialektische Multi-Roboter-Kollaboration mit gro√üen Sprachmodellen. Zhao Mandi, Shreeya Jain, Shuran Song (Columbia University) et al. arXiv. [ Papier ] [ Code ]

[2023/08] ProAgent: Aufbau einer proaktiven kooperativen KI mit gro√üen Sprachmodellen. Ceyao Zhang (Chinesische Universit√§t Hongkong, Shenzhen) et al. arXiv. [ Papier ] [ Code ]

3.1.2 Pers√∂nlichkeit
Erkenntnis
[2023/09] Suspicion Agent: Unvollkommene Informationsspiele mit Theory of Mind Aware spielen GPT-4 Jiaxian Gu oet al. arXiv. [ Papier ]
[2023/03] Maschinenpsychologie: Untersuchung neuer F√§higkeiten und Verhaltensweisen in gro√üen Sprachmodellen mit psychologischen Methoden. Thilo Hagendorff (Universit√§t Stuttgart) et al. arXiv. [ Papier ]
[2023/03] Geist trifft Maschine: Die kognitive Psychologie von GPT-4 entr√§tseln. Sifatkaur Dhingra (Nowrosjee Wadia College) et al. arXiv. [ Papier ]
[2022/07] Sprachmodelle zeigen menschen√§hnliche inhaltliche Auswirkungen auf das Denken. Ishita Dasgupta (DeepMind) et al. arXiv. [ Papier ]
[2022/06] Nutzung der kognitiven Psychologie zum Verst√§ndnis von GPT-3. Marcel Binz et al. arXiv. [ Papier ]
Emotion
[2023/07] Emotionale Intelligenz gro√üer Sprachmodelle. Xuena Wang (Tsinghua-Universit√§t) et al. arXiv. [ Papier ]
[2023/05] ChatGPT √ºbertrifft Menschen bei der Bewertung des emotionalen Bewusstseins. Zohar Elyoseph et al. Grenzen in der Psychologie. [ Papier ]
[2023/02] Empathische KI zur St√§rkung der Resilienz in Spielen. Reza Habibi (University of California) et al. arXiv. [ Papier ]
[2022/12] Computer sagt ‚ÄûNein‚Äú: Das Argument gegen empathische Konversations-KI. Alba Curry (Universit√§t Leeds) et al. ACL. [ Papier ]
Charakter
[2023/10] Character-LLM: Ein trainierbarer Agent f√ºr Rollenspiele. Yunfan Shao (Fudan-Universit√§t) et al. arXiv. [ Papier ] [ Code ]
[2023/07] Besitzen LLMs eine Pers√∂nlichkeit? Machen Sie den MBTI-Test zu einer erstaunlichen Bewertung f√ºr gro√üe Sprachmodelle. Keyu Pan (ByteDance) et al. arXiv. [ Papier ] [ Code ]
[2023/07] Pers√∂nlichkeitsmerkmale in gro√üen Sprachmodellen. Mustafa Safdari (DeepMind) et al. arXiv. [ Papier ] [ Code ]
[2022/12] Zeigt GPT-3 Psychopathie? Bewertung gro√üer Sprachmodelle aus psychologischer Sicht. Xingxuan Li (Alibaba) et al. arXiv. [ Papier ]
[2022/12] Identifizierung und Manipulation der Pers√∂nlichkeitsmerkmale von Sprachmodellen. Graham Caron et al. arXiv. [ Papier ]
3.2 Umgebung f√ºr die Agentengesellschaft
3.2.1 Textbasierte Umgebung
[2023/08] Hoodwinked: T√§uschung und Kooperation in einem textbasierten Spiel f√ºr Sprachmodelle. Aidan O'Gara (University of Southern California) et al. arXiv. [ Papier ] [ Code ]
[2023/03] CAMEL: Kommunikative Mittel zur ‚ÄûGeistes‚Äú-Erforschung einer gro√ü angelegten Sprachmodellgesellschaft. Guohao Li (King Abdullah University of Science and Technology) et al. arXiv. [ Papier ] [ Code ]
[2020/12] Textbasierte Spiele mit gesundem Menschenverstand spielen. Sahith Dambekodi (Georgia Institute of Technology) et al. arXiv. [ Papier ]
[2019/09] Interaktive Fiction-Spiele: Ein kolossales Abenteuer. Matthew Hausknecht (Microsoft Research) et al. AAAI. [ Papier ] [ Code ]
[2019/03] Sprechen und Handeln lernen in einem Fantasy-Text-Abenteuerspiel. Jack Urbanek (Facebook) et al. ACL. [ Papier ] [ Code ]
[2018/06] TextWorld: Eine Lernumgebung f√ºr textbasierte Spiele. Marc-Alexandre C√¥t√© (Microsoft Research) et al. IJCAI. [ Papier ] [ Code ]
3.2.2 Virtuelle Sandbox-Umgebung
[2023/11] JARVIS-1: Open-World-Multitasking-Agenten mit speichererweiterten multimodalen Sprachmodellen. ZiHao Wang (Universit√§t Peking) et al. arXiv. [ Papier ] [ Code ]
[2023/10] Humanoid Agents: Plattform zur Simulation menschen√§hnlicher generativer Agenten. Zhilin Wang (University of Washington und NVIDIA) et al. arXiv. [ Papier ] [ Code ] [ Demo ]
[2023/08] AgentSims: Eine Open-Source-Sandbox f√ºr die Evaluierung gro√üer Sprachmodelle. Jiaju Lin (PTA Studio) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/05] Training sozial ausgerichteter Sprachmodelle in der simulierten menschlichen Gesellschaft. Ruibo Liu (Dartmouth College) et al. arXiv. [ Papier ] [ Code ]
[2023/05] Voyager: Ein verk√∂rperter Agent mit offenem Ende und gro√üen Sprachmodellen. Guanzhi Wang (NVIDIA) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/04] Generative Agenten: Interaktive Simulakren menschlichen Verhaltens. Joon Sung Park (Stanford University) et al. arXiv. [ Papier ] [ Code ]
[2023/03] Plan4MC: Lernen und Planen zur Kompetenzverst√§rkung f√ºr Open-World-Minecraft-Aufgaben. Haoqi Yuan (PKU) et al. arXiv. [ Papier ] [ Projektseite ]
[2022/06] MineDojo: Aufbau offener verk√∂rperter Agenten mit Wissen im Internetma√üstab. Linxi Fan (NVIDIA) et al. NeurIPS. [ Papier ] [ Projektseite ]
3.2.3 Physische Umgebung
[2023/11] Ein verk√∂rperter generalistischer Agent in der 3D-Welt. Jiangyong Huang (BIGAI & Peking University) et al. arXiv. [ Papier ] [ Projektseite ]
[2023/09] RoboAgent: Generalisierung und Effizienz in der Robotermanipulation durch semantische Augmentationen und Action Chunking. Homanga Bharadhwaj (Carnegie Mellon University) et al. arXiv. [ Papier ] [ Projektseite ]
[2023/05] AVLEN: Audio-visuell-sprachliche verk√∂rperte Navigation in 3D-Umgebungen. Sudipta Paul et al. NeurIPS. [ Papier ]
[2023/03] PaLM-E: Ein verk√∂rpertes multimodales Sprachmodell. Danny Driess (Google) et al. ICML. [ Papier ] [ Projektseite ]
[2022/10] Interaktive Sprache: In Echtzeit mit Robotern sprechen. Corey Lynch (Google) et al. arXiv. [ Papier ] [ Code ]
3.3 Gesellschaftssimulation mit LLM-basierten Agenten
[2023/08] AgentSims: Eine Open-Source-Sandbox f√ºr die Evaluierung gro√üer Sprachmodelle. Jiaju Lin (PTA Studio) et al. arXiv. [ Papier ] [ Projektseite ] [ Code ]
[2023/07] S 3 : Simulationssystem f√ºr soziale Netzwerke mit durch gro√üe Sprachmodelle unterst√ºtzten Agenten. Chen Gao (Tsinghua-Universit√§t) et al. arXiv. [ Papier ]
[2023/07] Epidemiemodellierung mit generativen Agenten. Ross Williams (Virginia Tech) et al. arXiv. [ Papier ] [ Code ]
[2023/06] RecAgent: Ein neuartiges Simulationsparadigma f√ºr Empfehlungssysteme. Lei Wang (Renmin-Universit√§t China) et al. arXiv. [ Papier ]
[2023/05] Training sozial ausgerichteter Sprachmodelle in der simulierten menschlichen Gesellschaft. Ruibo Liu (Dartmouth College) et al. arXiv. [ Papier ] [ Code ]
[2023/04] Generative Agenten: Interaktive Simulakren menschlichen Verhaltens. Joon Sung Park (Stanford University) et al. arXiv. [ Papier ] [ Code ]
[2022/08] Social Simulacra: Erstellung bev√∂lkerter Prototypen f√ºr Social Computing-Systeme. Joon Sung Park (Stanford University) et al. UIST. [ Papier ]
